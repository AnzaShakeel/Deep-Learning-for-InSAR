{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Input, Conv2D, MaxPooling3D, UpSampling3D, Activation, Dense, Reshape, Flatten,Concatenate\n",
    "from keras.layers import Conv2DTranspose, ConvLSTM2D, TimeDistributed, Lambda, Bidirectional, Add\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import h5py\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from generate_data import *\n",
    "from ALADDIn_model import *\n",
    "from lambda_layers import *\n",
    "from process_output import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa5c118",
   "metadata": {},
   "source": [
    "# Initialize input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5243997",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH =\"\"\n",
    "Time_seq_sz = 9\n",
    "N_IFG = 26\n",
    "Overlapping_epochs = 5\n",
    "input_img = Input(shape = (N_IFG, 256, 256, 1))  #input interferograms\n",
    "input_img_TS = Input(shape = (Overlapping_epochs, 256, 256, 1)) #input overlapping epoch time-series\n",
    "input_ts_ep = Input(shape = (Overlapping_epochs, 256, 256, 1), name = 'image_ts') #input overlapping epoch time-series\n",
    "input_img_ifgm = Input(shape = (N_IFG, 256, 256, 1), name = 'image_ifgm') #input interferograms\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2dca2f",
   "metadata": {},
   "source": [
    "# Define network architecture and load pre-trained model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1eae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALADDIn = Model(input_img, create_model(input_img)) # load network architecture of ALADDIn\n",
    "\n",
    "ALADDIn.compile(optimizer=tensorflow.keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, amsgrad=False), loss='mean_squared_error')\n",
    "file_name_model = 'Trained_models/ALADDIn.hdf5'  # pre-trained model file name\n",
    "layer_output = ALADDIn.get_layer('TS').output     # get output for epoch time-series\n",
    "ALADDIn_intermediate_model = Model(inputs=ALADDIn.input,outputs=layer_output)\n",
    "ALADDIn_intermediate_model.load_weights(file_name_model) # load pre-trained ALADDIn mode\n",
    "print(ALADDIn_intermediate_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875ba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### break layers from ALADDIN's decoder\n",
    "ALADDIn_break_decoder = Model(inputs=ALADDIn.input, outputs=ALADDIn_intermediate_model.layers[43].output)\n",
    "print(ALADDIn_break_decoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TS_feat = ALADDIn_break_decoder(input_img_ifgm)  ### features for overlapping sequence\n",
    "\n",
    "### separate features of first 5 and last 4 epochs\n",
    "First_5_Ep = Lambda(merge_TS, name ='merge_TS')(TS_feat)\n",
    "Last_4_Ep = Lambda(merge_TS_end, name ='merge_TS_end')(TS_feat)\n",
    "\n",
    "### define model (encoder) for overlapping epochs input of previous sequence\n",
    "x1_ts = TimeDistributed(Conv2D(32, (5, 5), strides=4, activation=\"tanh\", padding=\"same\"), batch_input_shape=(None, 5, 256, 256, 1))(input_img_TS)\n",
    "x1_ts = LayerNormalization()(x1_ts)\n",
    "x1_ts = TimeDistributed(Conv2D(64, (5, 5), strides=2, activation=\"tanh\", padding=\"same\"))(x1_ts)\n",
    "x1_ts = LayerNormalization()(x1_ts)\n",
    "    \n",
    "x1_ts = ConvLSTM2D(64, (3, 3), activation='tanh', padding=\"same\", return_sequences=True)(x1_ts)\n",
    "x1_ts = LayerNormalization()(x1_ts)\n",
    "\n",
    "t_half_2_t_half = Model(inputs = input_img_TS, outputs = x1_ts, name = 'TS_to_TS')\n",
    "print(t_half_2_t_half.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input overlapping epochs from previous sequence\n",
    "half_ts_feat = t_half_2_t_half(input_ts_ep)\n",
    "\n",
    "### Add features of overlapping epochs \n",
    "filtered_f_5_ep = Add()([First_5_Ep, half_ts_feat])\n",
    "\n",
    "### Join back the filtered epochs and last 4 epochs & pass it on to the decoder\n",
    "m_TS = Concatenate(axis=1)([filtered_f_5_ep, Last_4_Ep])\n",
    "\n",
    "x15 = TimeDistributed(Conv2DTranspose(128, (3, 3), activation=\"gelu\",padding=\"same\", kernel_initializer='glorot_normal'), batch_input_shape=(None, 9, 256, 256, 1))(m_TS)\n",
    "x15 = LayerNormalization()(x15)\n",
    "c7 = Concatenate(axis=-1)([x15, m_TS])\n",
    "x16 = TimeDistributed(Conv2DTranspose(128, (3, 3), strides =2, activation=\"gelu\",padding=\"same\", kernel_initializer='glorot_normal'))(c7)\n",
    "x16 = LayerNormalization()(x16)\n",
    "x17 = TimeDistributed(Conv2DTranspose(64, (3, 3), activation=\"gelu\", padding=\"same\", kernel_initializer='glorot_normal'))(x16)\n",
    "x17 = LayerNormalization()(x17)\n",
    "c8 = Concatenate(axis=-1)([x17, x16])\n",
    "x18 = TimeDistributed(Conv2DTranspose(64, (3, 3), strides =2, activation=\"gelu\", padding=\"same\", kernel_initializer='glorot_normal'))(c8)\n",
    "x18 = LayerNormalization()(x18)\n",
    "x19 = TimeDistributed(Conv2DTranspose(32, (3, 3), strides =2, activation=\"gelu\", padding=\"same\", kernel_initializer='glorot_normal'))(x18)\n",
    "x19 = LayerNormalization()(x19)\n",
    "    \n",
    "TS = TimeDistributed(Conv2D(1, (1, 1), activation=\"linear\", padding=\"same\", kernel_initializer='glorot_normal'), name = 'TS_Final')(x19)    \n",
    "\n",
    "Temporal_self_attention = Model(inputs = [input_img_ifgm, input_ts_ep], outputs = [TS, TS])\n",
    "print(Temporal_self_attention.summary())\n",
    "Temporal_self_attention.compile(optimizer=tensorflow.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False), loss=['mean_squared_error', 'mean_squared_error'])\n",
    "\n",
    "file_name_model_synth = 'Trained_models/Temporal_self_attention.hdf5' \n",
    "Temporal_self_attention.load_weights(file_name_model_synth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3661a2b7",
   "metadata": {},
   "source": [
    "# Test model for earthquake of Mw 5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real earthquake 5.7\n",
    "import tensorflow as tf\n",
    "\n",
    "lines_test = [line.rstrip('\\\\n') for line in open('EQ_data_20_03_2019_text_file.txt')] #read text file that contains location and names of data\n",
    "data_folder_name = 'Turkey_EQ_data_20_03_2019'\n",
    "all_indices = list(np.arange(len(lines_test)))\n",
    "grp_seq_each_v_patch = 182  # Total data: 7 Interferrogram data sequences of size 26x256x256 = 7 x 26 =128 (change as per test data)\n",
    "Total_synth_v_locations = 1 # Total patch locations = 1 (change this variable as per test data)\n",
    "sh_indices_ts = all_indices[0 : ]\n",
    "iterations_ts = np.int((Total_synth_v_locations) * grp_seq_each_v_patch/N_IFG) # number of iterations = number of data sequences\n",
    "\n",
    "output_path = ('EQ_5.7_Output/')  # name of output folder\n",
    "\n",
    "    \n",
    "cc = 0 # counter set for patch locations greater than 1 \n",
    "for i in range(0,Total_synth_v_locations):\n",
    "    for ii in range(0,np.int(grp_seq_each_v_patch/N_IFG)):\n",
    "            \n",
    "        count_value = np.int(ii+cc)\n",
    "       \n",
    "        startIfg = count_value*N_IFG\n",
    "        endIfg = startIfg + N_IFG\n",
    "        \n",
    "      \n",
    "        test_image_path = lines_test[sh_indices_ts[startIfg]]   \n",
    "        test_image_patchname = data_folder_name\n",
    "\n",
    "        test_set = generator(sh_indices_ts,lines_test, count_value)\n",
    "        print(test_image_patchname, 'Sequence Number: ', ii)\n",
    "                 \n",
    "        if ii == 0:\n",
    "            ts_5 = ALADDIn_intermediate_model.predict(test_set)\n",
    "            ts_5 = ts_5[:,0:5,:,:,:]\n",
    "            TS_h, TS_f = Temporal_self_attention.predict([test_set, ts_5],batch_size=1) \n",
    "            IFG_pred = create_IFG(TS_f)\n",
    "                \n",
    "        if ii > 0:\n",
    "            test_set_p = generator(sh_indices_ts,lines_test, count_value-1)\n",
    "            ts_5p_h, ts_5p_f = Temporal_self_attention.predict([test_set_p, ts_5])\n",
    "            ts_5 = ts_5p_f[:,4:,:,:,:]\n",
    "            TS_h, TS_f = Temporal_self_attention.predict([test_set, ts_5],batch_size=1) \n",
    "            IFG_pred = create_IFG(TS_f)\n",
    "           \n",
    "        \n",
    "        sub_folder_path = output_path + test_image_patchname + '/' + str(ii) + '_ifg/'\n",
    "        if not os.path.exists(sub_folder_path):\n",
    "            os.makedirs(sub_folder_path)\n",
    "\n",
    "        save_IFG(startIfg, endIfg, lines_test, sh_indices_ts, test_set, IFG_pred, sub_folder_path) ## save all input and output for comparison (GT = ground truth or input interferograms, REC = reconstructed interferograms, RES = residual interferograms (GT- REC)) )\n",
    "            \n",
    "        \n",
    "        sub_folder_path1 = output_path + test_image_patchname + '/' + str(ii) + '_TS/'\n",
    "        if not os.path.exists(sub_folder_path1):\n",
    "            os.makedirs(sub_folder_path1)\n",
    "           \n",
    "        TS_names = get_names_TS(startIfg, endIfg, lines_test, sh_indices_ts)\n",
    "        \n",
    "        save_EPOCHS(TS_names, TS_f, sub_folder_path1) ## save output epoch time-series\n",
    "            \n",
    "                    \n",
    "    #cc = cc + iterations_ts  ## uncomment and increment this counter if testing for greater than 1 patch locations\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a9f63",
   "metadata": {},
   "source": [
    "# Test model for earthquake with shuttling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bacf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutteling F1 F2 F3 B3 B2 B1 real eq\n",
    "import tensorflow as tf\n",
    "\n",
    "shuttling_itr = 2 # number of times you want to shuttle\n",
    "lines_test = [line.rstrip('\\\\n') for line in open('EQ_data_20_03_2019_text_file.txt')] # open text file and read data\n",
    "data_folder_name = 'Turkey_EQ_data_20_03_2019'\n",
    "all_indices = list(np.arange(len(lines_test)))\n",
    "grp_seq_each_v_patch = 182 # Total data: 7 Interferrogram data sequences of size 26x256x256 = 7 x 26 =128 (change as per test data)\n",
    "Total_synth_v_locations = 1 # Total patch locations = 1 (change this variable as per test data) \n",
    "sh_indices_ts = all_indices[0 : ]\n",
    "iterations_ts = np.int((Total_synth_v_locations) * grp_seq_each_v_patch/N_IFG) #number of iterations = number of data sequences\n",
    "\n",
    "output_path = ('EQ_5.7_Output_SHUTTLING/') # name of output folder\n",
    "\n",
    "cc = 0\n",
    "    \n",
    "for i in range(0,Total_synth_v_locations):\n",
    "    for shtl in range(0,shuttling_itr):\n",
    "        for ii in range(0,np.int(grp_seq_each_v_patch/N_IFG)):\n",
    "                    \n",
    "            count_value = np.int(ii+cc)\n",
    "                    \n",
    "            startIfg = count_value*N_IFG\n",
    "            endIfg = startIfg + N_IFG\n",
    "                 \n",
    "            test_image_path = lines_test[sh_indices_ts[startIfg]]    \n",
    "            test_image_patchname = data_folder_name\n",
    "            \n",
    "            print(test_image_patchname,'Forward Shuttle number: ', shtl, 'Sequnce number: ', ii)\n",
    "\n",
    "                 \n",
    "            test_set = generator(sh_indices_ts,lines_test, count_value)\n",
    "                    \n",
    "            if shtl == 0:\n",
    "                if ii == 0:\n",
    "                    ts_5 = ALADDIn_intermediate_model.predict(test_set)\n",
    "                    ts_5 = ts_5[:,0:5,:,:,:]\n",
    "                    TS_h, TS_f = Temporal_self_attention.predict([test_set, ts_5],batch_size=1) \n",
    "                    IFG_pred = create_IFG(TS_f)\n",
    "    \n",
    "                     \n",
    "                if ii > 0:\n",
    "                    ts_5 = TS_f[:,4:,:,:,:]\n",
    "                    TS_h, TS_f = Temporal_self_attention.predict([test_set, ts_5],batch_size=1) \n",
    "                    IFG_pred = create_IFG(TS_f)\n",
    " \n",
    "                \n",
    "            if shtl > 0:\n",
    "                if ii == 0:\n",
    "                    ts_5[:,4,:,:,:] = TS_f[:,4,:,:,:]\n",
    "                    ts_5[:,3,:,:,:] = TS_f[:,5,:,:,:]\n",
    "                    ts_5[:,2,:,:,:] = TS_f[:,6,:,:,:]\n",
    "                    ts_5[:,1,:,:,:] = TS_f[:,7,:,:,:]\n",
    "                    ts_5[:,0,:,:,:] = TS_f[:,8,:,:,:]\n",
    "                    TS_h, TS_f = Temporal_self_attention.predict([test_set, ts_5],batch_size=1) \n",
    "                    IFG_pred = create_IFG(TS_f)\n",
    "                    #print(test_set.shape)\n",
    "                    #print(IFG_pred.shape) \n",
    "                            \n",
    "                if ii > 0:\n",
    "                    ts_5 = TS_f[:,4:,:,:,:]\n",
    "                    TS_h, TS_f = Temporal_self_attention.predict([test_set, ts_5],batch_size=1) \n",
    "                    IFG_pred = create_IFG(TS_f) \n",
    "                            \n",
    "                            \n",
    "            sub_folder_path = output_path + test_image_patchname + '/F_shtl_' + str(shtl) + '/' + str(ii) + '_ifg/'\n",
    "                 \n",
    "            if not os.path.exists(sub_folder_path):\n",
    "                os.makedirs(sub_folder_path)\n",
    "                    \n",
    "                 \n",
    "            save_IFG(startIfg, endIfg, lines_test, sh_indices_ts, test_set, IFG_pred, sub_folder_path)\n",
    "\n",
    "                 \n",
    "            sub_folder_path1 = output_path + test_image_patchname + '/F_shtl_' + str(shtl) + '/' + str(ii) + '_TS/'\n",
    "            if not os.path.exists(sub_folder_path1):\n",
    "                os.makedirs(sub_folder_path1)\n",
    "                    \n",
    "               \n",
    "            TS_names = get_names_TS(startIfg, endIfg, lines_test, sh_indices_ts)\n",
    "        \n",
    "            save_EPOCHS(TS_names, TS_f, sub_folder_path1)\n",
    "                \n",
    "                        \n",
    "\n",
    "        for ii in range(0, np.int(grp_seq_each_v_patch/N_IFG)):\n",
    "            b_count_value =  count_value - ii\n",
    "                   \n",
    "            startIfg = b_count_value*N_IFG + N_IFG-1\n",
    "            endIfg = startIfg - N_IFG\n",
    "                    \n",
    "            bkwd_names_in = bkwd_names_indx(startIfg, endIfg)\n",
    "                 \n",
    "            test_image_path = lines_test[sh_indices_ts[startIfg]]    \n",
    "            test_image_patchname = data_folder_name\n",
    "                 \n",
    "            test_set = generator_bkwd(sh_indices_ts,lines_test, b_count_value)\n",
    "            print(test_image_patchname, 'Backward Shuttle number: ', shtl, 'Sequnce number: ', ii)\n",
    "                    \n",
    "            if ii == 0:\n",
    "                ts_5[:,0,:,:,:] = TS_f[:,8,:,:,:]\n",
    "                ts_5[:,1,:,:,:] = TS_f[:,7,:,:,:]\n",
    "                ts_5[:,2,:,:,:] = TS_f[:,6,:,:,:]\n",
    "                ts_5[:,3,:,:,:] = TS_f[:,5,:,:,:]\n",
    "                ts_5[:,4,:,:,:] = TS_f[:,4,:,:,:]\n",
    "                TS_h, TS_f = Temporal_self_attention.predict([test_set, ts_5],batch_size=1) \n",
    "                IFG_pred = create_IFG(TS_f)\n",
    "                 \n",
    "                                           \n",
    "            if ii > 0:\n",
    "                ts_5 = TS_f[:,4:,:,:,:]\n",
    "                TS_h, TS_f = Temporal_self_attention.predict([test_set, ts_5],batch_size=1) \n",
    "                IFG_pred = create_IFG(TS_f) \n",
    "                        \n",
    "            sub_folder_path = output_path + test_image_patchname + '/B_shtl_' + str(shtl) + '/' + str(ii) + '_ifg/'\n",
    "                 \n",
    "            if not os.path.exists(sub_folder_path):\n",
    "                os.makedirs(sub_folder_path)\n",
    "                    \n",
    "                    \n",
    "            save_IFG_backward(startIfg, endIfg, lines_test, sh_indices_ts, bkwd_names_in, test_set, IFG_pred, sub_folder_path)\n",
    "                    \n",
    "            sub_folder_path1 = output_path + test_image_patchname + '/B_shtl_' + str(shtl) + '/' + str(ii) + '_TS/'\n",
    "                    \n",
    "            if not os.path.exists(sub_folder_path1):\n",
    "                os.makedirs(sub_folder_path1)\n",
    "                         \n",
    "            TS_names = get_names_TS_backwards(startIfg, endIfg, lines_test, sh_indices_ts)\n",
    "            save_EPOCHS_BACKWARDS(TS_names, TS_f, sub_folder_path1)       \n",
    "             \n",
    "    #cc = cc + iterations_ts  ## uncomment and increment this counter if testing for greater than 1 patch locations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
